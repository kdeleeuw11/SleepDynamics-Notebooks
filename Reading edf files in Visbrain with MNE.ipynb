{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image, clear_output\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"color:blue;font-family:helvetica; font-size:3.5rem; font-weight:700;\">Reading edf files in Visbrain with MNE</span></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The objective of this notebook is to give an outline of how edf files are read in Visbrain using the MNE software. The main reason to use the MNE software is that MNE can handle data with channels which have multiple sampling frequencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues with MNE\n",
    "Currently I have found one issue which affects the interface between MNE and Visbrain. This is caused by the fact that when the values of channels are measured in $\\mu V$, MNE  converts the values to $V$, while Visbrain uses the actual values. This issue is addressed in the Visbrain software.  \n",
    "\n",
    "Also note that MNE does not have capabilities to read hypnogram files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing MNE from Visbrain\n",
    "Using the MNE software to read the data file is triggered by setting the parameter `use_mne=True` in the command `Sleep(data, use_mne=True).show()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test program\n",
    "To understand how Visbrain reads edf files, a program is debugged which reads an edf file and then plots the results. This program is:  \n",
    "```Python\n",
    "# Read edf file from library\n",
    "from visbrain import Sleep\n",
    "\n",
    "Sleep(\"/users/kees/sleepdynamics/sleep-edfx/SC4001E0-PSG.edf\", use_mne=True).show()```  \n",
    "\n",
    "The `SC4001E0-PSG.edf` file is the first polysomnography file in the Physionet sleep database.  \n",
    "\n",
    "`SC4001E0-PSG.edf` is the first file in the Physionet database. The plots generated by the Visbrain software can be visually compared with the plots from [PhysioBank ATM](https://physionet.org/cgi-bin/atm/ATM).  \n",
    "\n",
    "The program is initially run by pressing \"Cancel\" when the popup for a hypnogram file is shown.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Sleep(data=dfile, use_mne=True).show()`\n",
    "`sleep(data = dfile, use_mne=True).show()` is the second line in the test program.  \n",
    "\n",
    "This notebook deals with how the data is read using the MNE software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of program `sleep.py`\n",
    "The class`Sleep` which is called in the test program is a class defined in `sleep.py`. The parts in this class relevant to reading the data are:\n",
    "```Python\n",
    "\"\"\"Top Level Sleep class\"\"\"\n",
    "# import modules\n",
    "...\n",
    "class Sleep(PyQtModule, ReadSleepData, UiInit, Visuals, UiElements,\n",
    "            MouseEventControl):\n",
    "    def __init__(self, data=None, hypno=None, config_file=None,\n",
    "                 annotations=None, channels=None, sf=None, downsample=100.,\n",
    "                 axis=True, href=['art', 'wake', 'rem', 'n1', 'n2', 'n3'],\n",
    "                 preload=True, use_mne=False, kwargs_mne={}, verbose=None):\n",
    "...\n",
    "      ReadSleepData.__init__(self, data, channels, sf, hypno, href, preload,\n",
    "                               use_mne, downsample, kwargs_mne,\n",
    "                               annotations)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ReadSleepData`\n",
    "`ReadSleepData` is a class defined in `read_sleep.py`\n",
    "```Python\n",
    "class ReadSleepData(object):\n",
    "    \"\"\"Main class for reading sleep data.\"\"\"\n",
    "\n",
    "    def __init__(self, data, channels, sf, hypno, href, preload, use_mne,\n",
    "                 downsample, kwargs_mne, annotations):\n",
    "        # dialog window if data is none\n",
    "        ...\n",
    "        if use_mne:\n",
    "            ...\n",
    "            args = mne_switch(file, ext, downsample, **kwargs_mne)\n",
    "        else:\n",
    "            ...\n",
    "            args = sleep_switch(file, ext, downsample)\n",
    "        ```\n",
    "\n",
    "In this situation, the `men_switch` function is accessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mne_switch`\n",
    "\n",
    "`mne_switch` is a function defined in the `mneio.py` program in Visbrain. `mneo.py` is part of the `io` directory of Visbrain. The relevant statements in `mne_switch` are:\n",
    "```Python\n",
    "def mne_switch(file, ext, downsample, preload=True, **kwargs):\n",
    "    \"\"\"Read sleep datasets using mne.io.\n",
    "    from mne import io\n",
    "\n",
    "    # Get full path :\n",
    "    path = file + ext\n",
    "\n",
    "    # Preload :\n",
    "    if preload is False:\n",
    "        preload = 'temp.dat'\n",
    "    kwargs['preload'] = preload\n",
    "\n",
    "    if ext.lower() in ['.edf', '.bdf', '.gdf']:  # EDF / BDF / GDF\n",
    "        raw = io.read_raw_edf(path, **kwargs)```\n",
    "\n",
    "The parameters when accessing `io` in MNE` are:\n",
    "- `path = '/users/kees/sleepdynamics/sleep-edfx/SC4001E0-PSG.edf'`\n",
    "- `kwargs = {'preload': True}`  \n",
    "\n",
    "\n",
    "`raw` is what is coming back from MNE. The important attributes are:\n",
    "- `raw.info`: the instant of `mne.io.meas_info.Info` which contains the header data\n",
    "- `raw_data`: the raw data\n",
    "- `raw.raw_extras`: additional header data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture for reading edf files in MNE\n",
    "With the statement:\n",
    "```Python\n",
    "    from mne import io```\n",
    "    \n",
    "a number of modules are imported. The important line here is:\n",
    "```Python\n",
    "from .edf import read_raw_edf, find_edf_events```\n",
    "\n",
    "This imports the `edf.py` program from the directory `mne/io/edf`. The `edf.py` program contains one class and a number of functions:\n",
    "- classes:\n",
    " - `RawEDF`\n",
    "- relevant functions:\n",
    " - `read_raw_edf` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in MNE\n",
    "## `read_raw_edf`\n",
    "The function `read_raw_edf` in `edf.py` does the following:\n",
    "```Python\n",
    "def read_raw_edf(input_fname, montage=None, eog=None, misc=None,\n",
    "                 stim_channel='auto', annot=None, annotmap=None, exclude=(),\n",
    "                 preload=False, verbose=None):\n",
    "    \"\"\"Reader function for EDF+, BDF, GDF conversion to FIF\"\"\"\n",
    "   return RawEDF(input_fname=input_fname, montage=montage, eog=eog, misc=misc,\n",
    "                  stim_channel=stim_channel, annot=annot, annotmap=annotmap,\n",
    "                  exclude=exclude, preload=preload, verbose=verbose)```\n",
    "                  \n",
    "\n",
    "The parameters are:\n",
    "- `input_frame = '/users/kees/sleepdynamics/sleep-edfx/SC4001E0-PSG.edf'`\n",
    "\n",
    "This step returns the instance of `RawEDF` with as most important attributes:\n",
    "- `info` header information\n",
    "- `_data`: the raw data\n",
    "- `_raw_extras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RawEDF`\n",
    "`RawEDF` is a class in `edf.py` and has as parent `BaseRaw` from `base.py`.  \n",
    "\n",
    "The relevant statements are:\n",
    "```Python\n",
    "class RawEDF(BaseRaw):\n",
    "    \"\"\"Raw object from EDF, EDF+, BDF file\"\"\"\n",
    "        def __init__(self, input_fname, montage, eog=None, misc=None,\n",
    "                 stim_channel=True, annot=None, annotmap=None, exclude=(),\n",
    "                 preload=False, verbose=None):\n",
    "        \n",
    "        input_fname = os.path.abspath(input_fname)\n",
    "        info, edf_info = _get_info(input_fname, stim_channel, annot,\n",
    "                                   annotmap, eog, misc, exclude, preload)\n",
    "        \n",
    "        last_samps = [edf_info['nsamples'] - 1]\n",
    "        super(RawEDF, self).__init__(\n",
    "            info, preload, filenames=[input_fname], raw_extras=[edf_info],\n",
    "            last_samps=last_samps, orig_format='int', verbose=verbose)```\n",
    "            \n",
    "This creates an instance of `RawEDF` with many attributes. The most important are:\n",
    "- `self.info`\n",
    "- `self._data`\n",
    "- `self._raw_extras`  \n",
    "\n",
    "The two important statements here are:\n",
    "- ```Python\n",
    "info, edf_info = _get_info(input_fname, stim_channel, annot,\n",
    "                                   annotmap, eog, misc, exclude, preload)```\n",
    "- ```Python\n",
    "super(RawEDF, self).__init__(\n",
    "            info, preload, filenames=[input_fname], raw_extras=[edf_info],\n",
    "            last_samps=last_samps, orig_format='int', verbose=verbose)```\n",
    "                                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_info`\n",
    "`get_info` is a function in `edf.py` used to get the header information.  \n",
    "\n",
    "The relevant first part of this function is:\n",
    "```Python\n",
    "def _get_info(fname, stim_channel, annot, annotmap, eog, misc, exclude,\n",
    "              preload):\n",
    "    \"\"\"Extract all the information from the EDF+, BDF or GDF file.\"\"\"\n",
    "    if eog is None:\n",
    "        eog = []\n",
    "    if misc is None:\n",
    "        misc = []\n",
    "\n",
    "    # Read header from file\n",
    "    ext = os.path.splitext(fname)[1][1:].lower()\n",
    "    logger.info('%s file detected' % ext.upper())\n",
    "    if ext in ('bdf', 'edf'):\n",
    "        edf_info = _read_edf_header(fname, annot, annotmap, exclude)```\n",
    "        \n",
    " `_read_edf_header` is another function in `edf.py`.  \n",
    " \n",
    " The header info is read according to the edf format:  \n",
    " `edf_info` is declared as a dictionary and updated with `annot, annotmap, events=[]`.  \n",
    "\n",
    "The header data is read:\n",
    "- `patient` is declared as a dictionary and the following is entered:\n",
    " - `patient['id']` here: `X`\n",
    " - `patient['name']` here: `F`\n",
    "- `meas_id` is declared as a dictionary and the following is entered:\n",
    " - `meas_id[recording_id']` here `Startdate 24-APR-1989 X X X`\n",
    "- some date and time manipulations are basically the same as in Visbrian:  \n",
    "the only exception is: `century = 2000 if year < 50 else 1900` which leads to a better computation of the century\n",
    "- `date` here `datetime.datetime(1989, 4, 24, 16, 13)`\n",
    "- `n_records` here \n",
    "- `header_nbytes` here `2048`\n",
    "- `n_records` here `2650`\n",
    "- `record_length=np.array([float(fid.read(8)), 1.])` here `array([30.,  1.])`\n",
    "- `nchan` here `7`\n",
    "- `channels = list(range(nchan))` here `[0, 1, 2, 3, 4, 5, 6]` used in next statement\n",
    "- `ch_names = [fid.read(16).strip().decode() for ch in channels]` here  \n",
    "`['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']`\n",
    "- `exclude` gives names of channels to exclude if there are in `exclude`\n",
    "- transducers are read to exclude?\n",
    "- `units` are read for all channels and entered into `edf_info{'units]`:  \n",
    "```Python\n",
    "        units = [fid.read(8).strip().decode() for ch in channels]\n",
    "        edf_info['units'] = list()\n",
    "        include = list()\n",
    "        for i, unit in enumerate(units):\n",
    "            if i in exclude:\n",
    "                continue\n",
    "            if unit == 'uV':\n",
    "                edf_info['units'].append(1e-6)\n",
    "            else:\n",
    "                edf_info['units'].append(1)\n",
    "            include.append(i)```  \n",
    "here `[1e-06, 1e-06, 1e-06, 1, 1e-06, 1, 1]`\n",
    "- for all channels:\n",
    " - `physical_min` here `array([ -192.,  -197., -1009., -2048.,    -5.,    34., -2047.])`\n",
    " - `physical_max` here `array([ 192.,  196., 1009., 2047.,    5.,   40., 2048.])`\n",
    " - `digital_min` here `array([-2048., -2048., -2048., -2048., -2500., -2849., -2047.])`\n",
    " - `digital_max` here `array([2047., 2047., 2047., 2047., 2500., 2731., 2048.])`\n",
    " - `prefiltering` with exception of last channel (event marker) here  \n",
    " `['HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.5Hz LP:100Hz [enhanced cassette BW]', 'HP:0.03Hz LP:0.9Hz', 'HP:16Hz Rectification LP:0.7Hz', '']`\n",
    " - `highpass`  \n",
    " ```Python\n",
    "         highpass = np.ravel([re.findall(r'HP:\\s+(\\w+)', filt)\n",
    "                             for filt in prefiltering])```\n",
    "  here: `array([], dtype=float64)`\n",
    " - `lowpass` similar to but search on `LP` instead of `HP`\n",
    "- populate `edf_info` with `edf_info.update` for:\n",
    " - 'chnames = chnames`\n",
    " - 'data_offset = header_nbytes`\n",
    " - `digital_max=digital_max`\n",
    " - `digital_min=digital_min`\n",
    " - `exclude=exclude`\n",
    " - `highpass=highpass`\n",
    " - `include=include`\n",
    " - `lowpass=lowpass`\n",
    " - `meas_date=calendar.timegm(date.utctimetuple())`\n",
    " - `n_records=n_records`\n",
    " - `n_samps=n_samps` \n",
    " - `nchan=nchan`\n",
    " - `subject_info=patient` \n",
    " - `physical_max=physical_max`\n",
    " - `physical_min=physical_min`\n",
    " - `record_length=record_length`\n",
    " - `subtype=subtype`  \n",
    " \n",
    "For the EEG file `SC4001E0-PSG.edf`, the values of `edf_info` are:\n",
    "```Text\n",
    "annot: None\n",
    "annotmap: None\n",
    "events: []\n",
    "units: [1e-06, 1e-06, 1e-06, 1, 1e-06, 1, 1]\n",
    "ch_names: ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n",
    "data_offset: 2048\n",
    "digital_max: [2047. 2047. 2047. 2047. 2500. 2731. 2048.]\n",
    "digital_min: [-2048. -2048. -2048. -2048. -2500. -2849. -2047.]\n",
    "exclude: []\n",
    "highpass: []\n",
    "include: [0, 1, 2, 3, 4, 5, 6]\n",
    "lowpass: []\n",
    "meas_date: 609437580\n",
    "n_records: 2650\n",
    "n_samps: [3000 3000 3000   30   30   30   30]\n",
    "nchan: 7\n",
    "subject_info: {'id': 'X', 'name': 'F'}\n",
    "physical_max: [ 192.  196. 1009. 2047.    5.   40. 2048.]\n",
    "physical_min: [ -192.  -197. -1009. -2048.    -5.    34. -2047.]\n",
    "record_length: [30.  1.]\n",
    "subtype: edf```\n",
    "\n",
    "All information read into `edf_info` is directly taken from the header information of the edf file, with the exception of `units`. `units` in the header info is for the example:  \n",
    "`units: ['uV', 'uV', 'uV', '', 'uV', 'DegC', '']`  \n",
    "\n",
    "While in `edf_info` the `units` are:  \n",
    "`units: [1e-06, 1e-06, 1e-06, 1, 1e-06, 1, 1]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data for `ed_info` is read, the data is massaged and `info` is created. `info` is basically the header data which is given back to Visbrain. At this stage, I think the following points are relevant:\n",
    "- for each channel in numpy array:\n",
    " - `physical_ranges = edf_info['physical_max'] - edf_info['physical_min']`   \n",
    " here `array([ 384.,  393., 2018., 4095.,   10.,    6., 4095.])`\n",
    " - `cals = edf_info['digital_max'] - edf_info['digital_min']`  \n",
    " here `array([4095., 4095., 4095., 4095., 5000., 5580., 4095.])`\n",
    "- a list of dictionaries of eeg channels is created:\n",
    "```Python\n",
    "    chs = list()\n",
    "    pick_mask = np.ones(len(ch_names))\n",
    "    for idx, ch_info in enumerate(zip(ch_names, physical_ranges, cals)):\n",
    "        ch_name, physical_range, cal = ch_info\n",
    "        chan_info = {}\n",
    "        chan_info['cal'] = cal\n",
    "        chan_info['logno'] = idx + 1\n",
    "        chan_info['scanno'] = idx + 1\n",
    "        chan_info['range'] = physical_range\n",
    "        chan_info['unit_mul'] = 0.\n",
    "        chan_info['ch_name'] = ch_name\n",
    "        chan_info['unit'] = FIFF.FIFF_UNIT_V\n",
    "        chan_info['coord_frame'] = FIFF.FIFFV_COORD_HEAD\n",
    "        chan_info['coil_type'] = FIFF.FIFFV_COIL_EEG\n",
    "        chan_info['kind'] = FIFF.FIFFV_EEG_CH\n",
    "        chan_info['loc'] = np.zeros(12)\n",
    "        if ch_name in eog or idx in eog or idx - nchan in eog:\n",
    "            chan_info['coil_type'] = FIFF.FIFFV_COIL_NONE\n",
    "            chan_info['kind'] = FIFF.FIFFV_EOG_CH\n",
    "            pick_mask[idx] = False\n",
    "        if ch_name in misc or idx in misc or idx - nchan in misc:\n",
    "            chan_info['coil_type'] = FIFF.FIFFV_COIL_NONE\n",
    "            chan_info['kind'] = FIFF.FIFFV_MISC_CH\n",
    "            pick_mask[idx] = False\n",
    "        check1 = stim_channel == ch_name\n",
    "        check2 = stim_channel == idx\n",
    "        check3 = nchan > 1\n",
    "        stim_check = np.logical_and(np.logical_or(check1, check2), check3)\n",
    "        if stim_check:\n",
    "            chan_info['coil_type'] = FIFF.FIFFV_COIL_NONE\n",
    "            chan_info['unit'] = FIFF.FIFF_UNIT_NONE\n",
    "            chan_info['kind'] = FIFF.FIFFV_STIM_CH\n",
    "            pick_mask[idx] = False\n",
    "            chan_info['ch_name'] = 'STI 014'\n",
    "            ch_names[idx] = chan_info['ch_name']\n",
    "            edf_info['units'][idx] = 1\n",
    "            if isinstance(stim_channel, str):\n",
    "                stim_channel = idx\n",
    "        if tal_channel is not None and idx in tal_channel:\n",
    "            chan_info['range'] = 1\n",
    "            chan_info['cal'] = 1\n",
    "            chan_info['coil_type'] = FIFF.FIFFV_COIL_NONE\n",
    "            chan_info['unit'] = FIFF.FIFF_UNIT_NONE\n",
    "            chan_info['kind'] = FIFF.FIFFV_MISC_CH\n",
    "            pick_mask[idx] = False\n",
    "        chs.append(chan_info)```\n",
    "- the first dictionary in the list `chs` has the following values:\n",
    "```Text\n",
    "cal: 4095.0\n",
    "logno: 1\n",
    "scanno: 1\n",
    "range: 384.0\n",
    "unit_mul: 0.0\n",
    "ch_name: EEG Fpz-Cz\n",
    "unit: 107\n",
    "coord_frame: 4\n",
    "coil_type: 1\n",
    "kind: 2\n",
    "loc: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]```\n",
    "- the other entries in the list `chs`  differ in:\n",
    " - `cal` which is the `cals` computed above\n",
    " - `logno` and `scanno` which is a sequential numbering\n",
    " - `range` is `physcial_range` computed above\n",
    " - `ch_name`\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are:\n",
    "- update of `info_edf` for `max_samp`:\n",
    "```Python    \n",
    "        if any(pick_mask):\n",
    "        picks = [item for item, mask in zip(range(nchan), pick_mask) if mask]\n",
    "        edf_info['max_samp'] = max_samp = n_samps[picks].max()```  \n",
    "all channels are in `pick_mask`. Here `edf_info['max_samp']=3000`\n",
    "- `sfreq` is computed as  \n",
    "```Python\n",
    "    data_samps = n_samps\n",
    "    sfreq = data_samps.max() * edf_info['record_length'][1] / edf_info['record_length'][0]```\n",
    "here `edf_info['record_length'] = [30,1]` and `data_samps.max()=3000`. --> `sfreq= 100`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing is that `info` is created as a dictionary through:\n",
    "```Python\n",
    "    info = _empty_info(sfreq)```  \n",
    "    \n",
    "- in `_empty_info`, a class in `meas_info.py`, a number of `_none_keys` and a number of `_list_keys` are defined as tuples\n",
    "- `info` is defined as an instance of `Info()` so it inherits all the methods of `Info`. `Info` is a class with parent `dict` and is also in `meas_info.py`. So `info` is basically a directory \n",
    "- the `-non_keys` and `'list_keys` are now set up in `'info` and some values are set:  \n",
    "```Python\n",
    "def _empty_info(sfreq):\n",
    "    \"\"\"Create an empty info dictionary.\"\"\"\n",
    "    from ..transforms import Transform\n",
    "    _none_keys = (\n",
    "        'acq_pars', 'acq_stim', 'buffer_size_sec', 'ctf_head_t', 'description',\n",
    "        'dev_ctf_t', 'dig', 'experimenter',\n",
    "        'file_id', 'highpass', 'hpi_subsystem', 'kit_system_id',\n",
    "        'line_freq', 'lowpass', 'meas_date', 'meas_id', 'proj_id', 'proj_name',\n",
    "        'subject_info', 'xplotter_layout',\n",
    "    )\n",
    "    _list_keys = ('bads', 'chs', 'comps', 'events', 'hpi_meas', 'hpi_results',\n",
    "                  'projs', 'proc_history')\n",
    "    info = Info()\n",
    "    for k in _none_keys:\n",
    "        info[k] = None\n",
    "    for k in _list_keys:\n",
    "        info[k] = list()\n",
    "    info['custom_ref_applied'] = False\n",
    "    info['dev_head_t'] = Transform('meg', 'head')\n",
    "    info['highpass'] = 0.\n",
    "    info['sfreq'] = float(sfreq)\n",
    "    info['lowpass'] = info['sfreq'] / 2.\n",
    "    info._update_redundant()\n",
    "    info._check_consistency()\n",
    "    return info```\n",
    "- here:\n",
    " - `info['dev_head_t']`: a $4\\times 4$ array\n",
    " - `info['highpass'] = 0`\n",
    " - `info['sfreq'] = float(sfreq)=100.0`; transferred when creating `_empty_invo(sfreq)`\n",
    " - `info['lowpass'] = info['sfreq'] / 2 = 50.`\n",
    "- after `info` is returned with keys and some values, other values are updated:\n",
    "```Text\n",
    "info\n",
    "<Info | 17 non-empty fields\n",
    "    bads : list | 0 items\n",
    "    buffer_size_sec : float | 1.0\n",
    "    ch_names : list | EEG Fpz-Cz, EEG Pz-Oz, EOG horizontal, Resp oro-nasal, EMG submental, Temp rectal, Event marker\n",
    "    chs : list | 7 items (EEG: 7)  \n",
    "      this list contains for each channel a dictionary with info for that channel. \n",
    "      The most important ones are:\n",
    "      - cal first channel: 4095\n",
    "      - range first channel: 384\n",
    "    comps : list | 0 items\n",
    "    custom_ref_applied : bool | False\n",
    "    dev_head_t : Transform | 3 items\n",
    "    events : list | 0 items\n",
    "    highpass : float | 0.0 Hz\n",
    "    hpi_meas : list | 0 items\n",
    "    hpi_results : list | 0 items\n",
    "    lowpass : float | 50.0 Hz\n",
    "    meas_date : int | 609437580\n",
    "    nchan : int | 7\n",
    "    proc_history : list | 0 items\n",
    "    projs : list | 0 items\n",
    "    sfreq : float | 100.0 Hz\n",
    "    acq_pars : NoneType\n",
    "    acq_stim : NoneType\n",
    "    ctf_head_t : NoneType\n",
    "    description : NoneType\n",
    "    dev_ctf_t : NoneType\n",
    "    dig : NoneType\n",
    "    experimenter : NoneType\n",
    "    file_id : NoneType\n",
    "    hpi_subsystem : NoneType\n",
    "    kit_system_id : NoneType\n",
    "    line_freq : NoneType\n",
    "    meas_id : NoneType\n",
    "    proj_id : NoneType\n",
    "    proj_name : NoneType\n",
    "    subject_info : NoneType\n",
    "    xplotter_layout : NoneType```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data\n",
    "The next steps are (line 173 in `__init__` in `RawEDF`:\n",
    "```Python\n",
    "        last_samps = [edf_info['nsamples'] - 1]   # here: 79449999\n",
    "        super(RawEDF, self).__init__(\n",
    "            info, preload, filenames=[input_fname], raw_extras=[edf_info]```\n",
    "This sits in `BaseRaw`:\n",
    "```Python\n",
    "        self._last_samps = np.array(last_samps)  \n",
    "        self._first_samps = np.array(first_samps)\n",
    "        info._check_consistency()  # make sure subclass did a good job\n",
    "        self.info = info\n",
    "        cals = np.empty(info['nchan'])\n",
    "        for k in range(info['nchan']):\n",
    "            cals[k] = info['chs'][k]['range'] * info['chs'][k]['cal']  # how cals is computed see below\n",
    "        bad = np.where(cals == 0)[0]\n",
    "        if len(bad) > 0:\n",
    "            raise ValueError('Bad cals for channels %s'\n",
    "                             % dict((ii, self.ch_names[ii]) for ii in bad))\n",
    "        self.verbose = verbose\n",
    "        self._cals = cals\n",
    "        self._raw_extras = list(raw_extras)\n",
    "        # deal with compensation (only relevant for CTF data, either CTF\n",
    "        # reader or MNE-C converted CTF->FIF files)\n",
    "        self._read_comp_grade = self.compensation_grade  # read property\n",
    "        if self._read_comp_grade is not None:\n",
    "            logger.info('Current compensation grade : %d'\n",
    "                        % self._read_comp_grade)\n",
    "        self._comp = None\n",
    "        self._filenames = list(filenames)\n",
    "        self.orig_format = orig_format\n",
    "        self._projectors = list()\n",
    "        self._projector = None\n",
    "        self._dtype_ = dtype\n",
    "        self.annotations = None\n",
    "        # If we have True or a string, actually do the preloading\n",
    "        self._update_times()\n",
    "        if load_from_disk:\n",
    "            self._preload_data(preload)```  \n",
    "            \n",
    "Here the part from above where `cals` is computed:\n",
    "```Python\n",
    "        cals = np.empty(info['nchan'])\n",
    "        for k in range(info['nchan']):\n",
    "            cals[k] = info['chs'][k]['range'] * info['chs'][k]['cal']```\n",
    "here: \n",
    "- `info['nchan']=7`\n",
    "- `info['chs'][k]['range']` is the physical range = physical max - physical min; 1st channel: 384\n",
    "- `info['chs'][k]['cal']` is cal = digital max - digital min; 1st channel: 4095\n",
    "- `cals = range*cal` first channel: 1572480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now `self._preload_data(preload)`\n",
    "\n",
    "- what I think is relevant here is:\n",
    " - `self._last_samp`: 7949999\n",
    " - `self._first_samps`: 0\n",
    " - `self.info`\n",
    " - `self._cals`: `array([ 1572480.,  1609335.,  8263710., 16769025.,    50000.,    33480., 16769025.])`\n",
    " - `self._raw_extras` is `info_edf`\n",
    " - `self._preload_data(preload)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slice(None, None, None)`_preload_data` is a method of `BaseRaw` in `base.py`. The important statement is:\n",
    "- `self._data = self._read_segment(data_buffer=data_buffer)`  \n",
    "this is a method in `BaseRaw`  \n",
    "some values for the statements 460 - 525\n",
    "- `start = 0`\n",
    "- `stop = 7950000`\n",
    "- `n_sel_channels = 7`\n",
    "- `data_shape = (7, 7950000)`\n",
    "- `dtype = class 'numpy.float64`\n",
    "- `data = np.zeros(data_shape, dtype)`\n",
    "- `cumul_lens = np.concatenate(([0], np.array(self._raw_lengths, dtype='int')))` `array([   0,7950000])`\n",
    "- `cals = self._cals.ravel()[np.newaxis, :]`  \n",
    "here: `array([[ 1572480.,  1609335.,  8263710., 16769025.,    50000.,    33480., 16769025.]])`\n",
    "- `cals = cals.T[idx]`  \n",
    "- `start_file = 0`\n",
    "- `stop_file = 795000`\n",
    "- `'n_read = 795000`   \n",
    "\n",
    "Now at 508 in `_read_segment` of `BaseRaw`: read from necessary file\n",
    "```Python\n",
    "        offset = 0\n",
    "        for fi in np.nonzero(files_used)[0]:\n",
    "            start_file = self._first_samps[fi]\n",
    "            # first iteration (only) could start in the middle somewhere\n",
    "            if offset == 0:\n",
    "                start_file += start - cumul_lens[fi]\n",
    "            stop_file = np.min([stop - cumul_lens[fi] + self._first_samps[fi],\n",
    "                                self._last_samps[fi] + 1])\n",
    "            if start_file < self._first_samps[fi] or stop_file < start_file:\n",
    "                raise ValueError('Bad array indexing, could be a bug')\n",
    "            n_read = stop_file - start_file\n",
    "            this_sl = slice(offset, offset + n_read)\n",
    "            self._read_segment_file(data[:, this_sl], idx, fi,\n",
    "                                    int(start_file), int(stop_file),\n",
    "                                    cals, mult)\n",
    "            offset += n_read\n",
    "        return data```  \n",
    "        \n",
    "\n",
    " `_read_segment_file` is a method of `RawEDF`:  \n",
    " ```Python\n",
    "     def _read_segment_file(self, data, idx, fi, start, stop, cals, mult):\n",
    "        \"\"\"Read a chunk of raw data.\"\"\"```\n",
    "        \n",
    "the parameters are:\n",
    "- `data` an empty $7\\times 7950000$ array\n",
    "- `idx` `slice(None, None, None)`\n",
    "- `fi` = 0\n",
    "- `start` = 0\n",
    "- `stop` = 7950000\n",
    "- `cals` `array([ 1572480.,  1609335.,  8263710., 16769025.,    50000.,    33480., 16769025.])` but transposed\n",
    "- `mult` = None\n",
    "\n",
    "first statement: \n",
    "```Python\n",
    "        from scipy.interpolate import interp1d```  \n",
    "        \n",
    "additional parameters are determined from `self`. The most important:\n",
    "- `sel = np.arange(self.info['nchan'])[idx]` here `array([0, 1, 2, 3, 4, 5, 6])`\n",
    "- `n_samps = self._raw_extras[fi]['n_samps']` here `array([3000, 3000, 3000,   30,   30,   30,   30])`\n",
    "- `buf_len = int(self._raw_extras[fi]['max_samp'])` here = 3000\n",
    "- `sfreq = self.info['sfreq']` here = 100\n",
    "- `dtype = self._raw_extras[fi]['dtype_np']` here `<class 'numpy.int16'>`\n",
    "- `dtype_byte = self._raw_extras[fi]['dtype_byte']` here = 2\n",
    "- `data_offset = self._raw_extras[fi]['data_offset']` here = 2048  \n",
    "\n",
    "then gain constructor:  \n",
    "```Python\n",
    "        physical_range = np.array([ch['range'] for ch in self.info['chs']])\n",
    "        cal = np.array([ch['cal'] for ch in self.info['chs']])\n",
    "        cal = np.atleast_2d(physical_range / cal)  # physical / digital\n",
    "        gains = np.atleast_2d(self._raw_extras[fi]['units'])```\n",
    "\n",
    "- `pysical_range` here `array([ 384.,  393., 2018., 4095.,   10.,    6., 4095.])`\n",
    "- `cal` here before the second statement `array([ 384.,  393., 2018., 4095.,   10.,    6., 4095.])`\n",
    "- `cal` after the second statement `array([[0.09377289, 0.0959707 , 0.49279609, 1.        , 0.002     ,\n",
    "        0.00107527, 1.        ]])`\n",
    "- `gains` here `array([[1.e-06, 1.e-06, 1.e-06, 1.e+00, 1.e-06, 1.e+00, 1.e+00]])`  \n",
    "\n",
    "then physical dimension in $\\mu V$:\n",
    "```Python\n",
    "        physical_min = self._raw_extras[fi]['physical_min']\n",
    "        digital_min = self._raw_extras[fi]['digital_min']\n",
    "\n",
    "        offsets = np.atleast_2d(physical_min - (digital_min * cal)).T```\n",
    "\n",
    "- `physical_min` here `array([ -192.,  -197., -1009., -2048.,    -5.,    34., -2047.])`\n",
    "- `digital_min` here `array([-2048., -2048., -2048., -2048., -2500., -2849., -2047.])`\n",
    "- `offsets` here `array([[ 0.04688645, -0.45201465,  0.24639805,  0.,  0., 37.06344086,  0.]])` shown transposed\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough from 27 in `RawEDF` of `edf.py`:\n",
    "- they say they could read one EDF block at a time, but to speed it up, they need to read multiple blocks at once.\n",
    "- some manipulation about starts, offsets, etc\n",
    "- then at 253:\n",
    "```Python\n",
    "                # Read and reshape to (n_chunks_read, ch0_ch1_ch2_ch3...)\n",
    "                many_chunk = _read_ch(fid, subtype, ch_offsets[-1] * n_read,\n",
    "                                      dtype_byte, dtype).reshape(n_read, -1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `_read_ch` is defined on line 341 of `edf.py`\n",
    "- `def _read_ch(fid, subtype, samp, dtype_byte, dtype=None):\n",
    "    \"\"\"Read a number of samples for a single channel.\"\"\"`\n",
    "- the parameters are:\n",
    " - `fid` here  \n",
    " `<_io.FileIO name='/users/kees/sleepdynamics/sleep-edfx/SC4001E0-PSG.edf' mode='rb' closefd=True>`\n",
    " - `subtype`: here `edf`\n",
    " - `samp` here = 5234880\n",
    " - `dtype_byte` here = 2\n",
    " - `dtype` here = `<class 'numpy.int16'>`\n",
    " - then:  \n",
    " `ch_data = np.fromfile(fid, dtype=dtype, count=samp)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here the data is read in one chunck (how about the header data? skipped?\n",
    "- after the read the data is split into channels and we are ending up with an array `data` which has dimensions $7\\times 7950000$\n",
    "- then we have:  \n",
    "```Python\n",
    "        data *= cal.T[sel]  # scale\n",
    "        data += offsets[sel]  # offset\n",
    "        data *= gains.T[sel]  # apply units gain last```\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to `visbrain mne_switch` with `raw`. The data is in `raw._data` \n",
    "\n",
    "Here we have:  \n",
    "```Python\n",
    "    sf = raw.info['sfreq']\n",
    "    dsf, downsample = get_dsf(downsample, sf)```\n",
    "    \n",
    "This might be the point where things are going haywire. \n",
    "\n",
    "What is returned is:\n",
    "- `dsf` = 1\n",
    "- `downsample` = 100.0  \n",
    "\n",
    "What is returned from `mne_switch` is:\n",
    "- `sf` =100\n",
    "- `downsample` = 100\n",
    "- `dsf` = 1\n",
    "- `data[:,::dsf]`   this is a $7\\times 7950000$ array\n",
    "- 'channels`\n",
    "- `n` = 795000\n",
    "- `start_time`\n",
    "- `anot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It goes back to `ReadSleepData` where we get the following I/O:\n",
    "```Text\n",
    "\u001b[1m\u001b[1;37mINFO\u001b[0m | File successfully loaded (/users/kees/sleepdynamics/sleep-edfx/SC4001E0-PSG.edf):\n",
    "- Sampling-frequency : 100.00Hz\n",
    "- Number of time points (before down-sampling): 7950000\n",
    "- Down-sampling frequency : 100.00Hz\n",
    "- Number of time points (after down-sampling): 7950000\n",
    "- Number of channels : 7```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion from digital values to physical values\n",
    "`cals` is initially computed as the digital range. It is then entered into the header info as `cal` and the physical range is entered as `range` in the dictionary of header info per channel:\n",
    "```Python\n",
    "        chan_info['cal'] = cal\n",
    "        chan_info['range'] = physical_range```\n",
    "        \n",
    "Then `cals` is computed for each channel as the product of physical range and digital range and added as an attribute of `BaseRaw`:\n",
    "```Python\n",
    "        cals = np.empty(info['nchan'])\n",
    "        for k in range(info['nchan']):\n",
    "            cals[k] = info['chs'][k]['range'] * info['chs'][k]['cal']\n",
    "        self._cals = cals```\n",
    "        \n",
    "In `_read_segment_file`, `cal` is computed as the ratio between the physical range and the digital range. So `cal` has now the same values as `gain` in the previous section. Then `gains` is set to the units of measurement taken from the header info:  \n",
    "`array([[1.e-06, 1.e-06, 1.e-06, 1.e+00, 1.e-06, 1.e+00, 1.e+00]])`  \n",
    "\n",
    "Then `offsets` are calculated as `offsets = phys min - digital min*cal`.  \n",
    "\n",
    "After the data has been read, we get the conversion back to physical values as done in the previous section, but also the application of the units (`gains`):  \n",
    "```Python\n",
    "        data *= cal.T[sel]  # scale\n",
    "        data += offsets[sel]  # offset\n",
    "        data *= gains.T[sel]  # apply units gain last```\n",
    "        \n",
    "The first two statements are required for the conversion to physical. The last statement results to values in base units, e.g. $\\mu V$ for EEG channels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handing back data to Visbrain\n",
    "The last step is to hand back the data to Visbrain as `raw`. The two important attributes here of `raw` are:\n",
    "- `raw.info`: the header data\n",
    "- `raw._data`: the sample values (in base units)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling in MNE\n",
    "Resampling in MNE is not used when Visbrain uses MNE to read data files. It is here just to show how resampling is done in MNE.\n",
    "```Python\n",
    "def resample(x, up=1., down=1., npad=100, axis=-1, window='boxcar', n_jobs=1,\n",
    "             pad='reflect_limited', verbose=None):\n",
    "    \"\"\"Resample an array.\n",
    "\n",
    "    Operates along the last dimension of the array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : n-d array\n",
    "        Signal to resample.\n",
    "    up : float\n",
    "        Factor to upsample by.\n",
    "    down : float\n",
    "        Factor to downsample by.\n",
    "    npad : int | str\n",
    "        Number of samples to use at the beginning and end for padding.\n",
    "        Can be \"auto\" to pad to the next highest power of 2.\n",
    "    axis : int\n",
    "        Axis along which to resample (default is the last axis).\n",
    "    window : string or tuple\n",
    "        See :func:`scipy.signal.resample` for description.\n",
    "    n_jobs : int | str\n",
    "        Number of jobs to run in parallel. Can be 'cuda' if scikits.cuda\n",
    "        is installed properly and CUDA is initialized.\n",
    "    pad : str\n",
    "        The type of padding to use. Supports all :func:`numpy.pad` ``mode``\n",
    "        options. Can also be \"reflect_limited\" (default), which pads with a\n",
    "        reflected version of each vector mirrored on the first and last\n",
    "        values of the vector, followed by zeros.\n",
    "\n",
    "        .. versionadded:: 0.15\n",
    "    verbose : bool, str, int, or None\n",
    "        If not None, override default verbose level (see :func:`mne.verbose`\n",
    "        and :ref:`Logging documentation <tut_logging>` for more).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xf : array\n",
    "        x resampled.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This uses (hopefully) intelligent edge padding and frequency-domain\n",
    "    windowing improve scipy.signal.resample's resampling method, which\n",
    "    we have adapted for our use here. Choices of npad and window have\n",
    "    important consequences, and the default choices should work well\n",
    "    for most natural signals.\n",
    "\n",
    "    Resampling arguments are broken into \"up\" and \"down\" components for future\n",
    "    compatibility in case we decide to use an upfirdn implementation. The\n",
    "    current implementation is functionally equivalent to passing\n",
    "    up=up/down and down=1.\n",
    "    \"\"\"\n",
    "    from scipy.fftpack import fft, ifftshift, fftfreq, ifft\n",
    "    \n",
    "    from scipy.signal import get_window\n",
    "    # check explicitly for backwards compatibility\n",
    "    if not isinstance(axis, int):\n",
    "        err = (\"The axis parameter needs to be an integer (got %s). \"\n",
    "               \"The axis parameter was missing from this function for a \"\n",
    "               \"period of time, you might be intending to specify the \"\n",
    "               \"subsequent window parameter.\" % repr(axis))\n",
    "        raise TypeError(err)\n",
    "\n",
    "    # make sure our arithmetic will work\n",
    "    x = np.asanyarray(x)\n",
    "    ratio = float(up) / down\n",
    "    if axis < 0:\n",
    "        axis = x.ndim + axis\n",
    "    orig_last_axis = x.ndim - 1\n",
    "    if axis != orig_last_axis:\n",
    "        x = x.swapaxes(axis, orig_last_axis)\n",
    "    orig_shape = x.shape\n",
    "    x_len = orig_shape[-1]\n",
    "    if x_len == 0:\n",
    "        warn('x has zero length along last axis, returning a copy of x')\n",
    "        return x.copy()\n",
    "    bad_msg = 'npad must be \"auto\" or an integer'\n",
    "    if isinstance(npad, string_types):\n",
    "        if npad != 'auto':\n",
    "            raise ValueError(bad_msg)\n",
    "        # Figure out reasonable pad that gets us to a power of 2\n",
    "        min_add = min(x_len // 8, 100) * 2\n",
    "        npad = 2 ** int(np.ceil(np.log2(x_len + min_add))) - x_len\n",
    "        npad, extra = divmod(npad, 2)\n",
    "        npads = np.array([npad, npad + extra], int)\n",
    "    else:\n",
    "        if npad != int(npad):\n",
    "            raise ValueError(bad_msg)\n",
    "        npads = np.array([npad, npad], int)\n",
    "    del npad\n",
    "\n",
    "    # prep for resampling now\n",
    "    x_flat = x.reshape((-1, x_len))\n",
    "    orig_len = x_len + npads.sum()  # length after padding\n",
    "    new_len = int(round(ratio * orig_len))  # length after resampling\n",
    "    final_len = int(round(ratio * x_len))\n",
    "    to_removes = [int(round(ratio * npads[0]))]\n",
    "    to_removes.append(new_len - final_len - to_removes[0])\n",
    "    to_removes = np.array(to_removes)\n",
    "    # This should hold:\n",
    "    # assert np.abs(to_removes[1] - to_removes[0]) <= int(np.ceil(ratio))\n",
    "\n",
    "    # figure out windowing function\n",
    "    if window is not None:\n",
    "        if callable(window):\n",
    "            W = window(fftfreq(orig_len))\n",
    "        elif isinstance(window, np.ndarray) and \\\n",
    "                window.shape == (orig_len,):\n",
    "            W = window\n",
    "        else:\n",
    "            W = ifftshift(get_window(window, orig_len))\n",
    "    else:\n",
    "        W = np.ones(orig_len)\n",
    "    W *= (float(new_len) / float(orig_len))\n",
    "    W = W.astype(np.complex128)\n",
    "\n",
    "    # figure out if we should use CUDA\n",
    "    n_jobs, cuda_dict, W = setup_cuda_fft_resample(n_jobs, W, new_len)\n",
    "\n",
    "    # do the resampling using an adaptation of scipy's FFT-based resample()\n",
    "    # use of the 'flat' window is recommended for minimal ringing\n",
    "    if n_jobs == 1:\n",
    "        y = np.zeros((len(x_flat), new_len - to_removes.sum()), dtype=x.dtype)\n",
    "        for xi, x_ in enumerate(x_flat):\n",
    "            y[xi] = fft_resample(x_, W, new_len, npads, to_removes,\n",
    "                                 cuda_dict, pad)\n",
    "    else:\n",
    "        parallel, p_fun, _ = parallel_func(fft_resample, n_jobs)\n",
    "        y = parallel(p_fun(x_, W, new_len, npads, to_removes, cuda_dict, pad)\n",
    "                     for x_ in x_flat)\n",
    "        y = np.array(y)\n",
    "\n",
    "    # Restore the original array shape (modified for resampling)\n",
    "    y.shape = orig_shape[:-1] + (y.shape[1],)\n",
    "    if axis != orig_last_axis:\n",
    "        y = y.swapaxes(axis, orig_last_axis)\n",
    "\n",
    "    return y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
